\documentclass[bj, preprint]{imsart}
\RequirePackage[OT1]{fontenc}
\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}

\usepackage{amsthm,amsmath,natbib,booktabs,cleveref}
\newcommand{\cexp}[1]{\left<#1\right>}
\usepackage{bbm}
\newcommand{\onebb}{\mathbbm{1}}
\newcommand{\Ebb}{\mathbb{E}}

% put your definitions there:
\endlocaldefs
\input{../utils/preamble}


\begin{document}

\begin{frontmatter}

\title{{\Large STATS 507 Project Report:} \\ 
\bf \texttt{MovieLens} Datasets---Predicting and Analyzing User Ratings of Movies}
\runtitle{\texttt{MovieLens}---Predicting and Analyzing Movie Ratings}

\begin{aug}
\author{
\fnms{Trong Dat} 
\snm{Do}
\thanksref{a,e1}
\ead[label=e1,mark]{dodat@umich.edu}
}
\and
\author{
\fnms{Simon} 
\snm{Fontaine}
\thanksref{a,e2}
\ead[label=e2,mark]{simfont@umich.edu}
}
\address[a]{University of Michigan, Department of Statistics. West Hall, 1085 South University, Ann Arbor, MI, U.S.A., 48109. \printead{e1,e2}}
\runauthor{Trong Dat Do and Simon Fontaine}
\affiliation{University of Michigan, Department of Statistics}
\end{aug}

\vspace{2cm}

\begin{abstract}
\textbf{Summary.} The \texttt{MovieLens} datasets contain user ratings of movies as well as movie and user information. In this report, we consider four predictive models of the ratings based on the available information: $K$-nearest-neighbors, neural networks, matrix completion using singular value decomposition and  restricted Bolztmann machine. We tune all models to finally compare them on their out-of-sample performance: matrix completion produces the best testing metrics. Then, we propose two exploratory analysis methods in order to extract insight from the selected predictive model. All code and results can be found at \url{https://github.com/fontaine618/507-Project/}.
\end{abstract}

\end{frontmatter}


\newpage
\tableofcontents
\newpage
%------------------------------------------------------------------------------
\section{Introduction}\label{sec:intro}
%------------------------------------------------------------------------------
\subsection{The \texttt{MovieLens} Datasets}\label{subsec:dataset}

The \texttt{MovieLens} datasets \citep{harper2015MovieLensDatasetsHistory} contains user ratings of a variety of movies continuously collected starting from 1997. 
In addition to the \texttt{user}-\texttt{movie}-\texttt{rating} pairings, the datasets contains information about movie genres, word tagging of movies provided by users and user demographic information. 

We will consider the \texttt{MovieLens 100K Dataset}\footnote{Available at \url{https://grouplens.org/datasets/movielens/100k/}}, which is one of the multiple datasets provided by \texttt{GroupLens}\footnote{Organization website: \url{https://grouplens.org/}}. 
We will be interested in this particular dataset because it contains additional demographic information about the users in the dataset. 
To include tagging information, we also consider the \texttt{MovieLens Tag Genome Dataset}\footnote{Available at \url{https://grouplens.org/datasets/movielens/tag-genome/}}. 
Here is a summary of the contents of the datasets that will be used\footnote{From the \texttt{README.txt} file attached to the datasets (\url{http://files.grouplens.org/datasets/movielens/ml-100k-README.txt}, \url{http://files.grouplens.org/datasets/tag-genome/README.html)}}:

\begin{description}
	\item[\texttt{MovieLens 100K Dataset}] 
	The dataset was collected from the \texttt{MovieLens} website (\url{movielens.umn.edu}) between September 19th, 1997 through April 22nd, 1998. 
	It has been pre-processed and cleaned to include only examples where the users have made at least 20 ratings during the collection period and where demographic information are complete. 
	In the \texttt{u.data} file, there are \num{100000} ratings on the scale of 1 to 5, taking only integer values. 
	It contains the following entries: \texttt{user id}, \texttt{item id}, \texttt{rating}, \texttt{timestamp}. 
	In the \texttt{u.item} file, there are \num{1681} movies with the following information: \texttt{movie id}, \texttt{movie title}, \texttt{release date}, \texttt{IMDb URL} and 19 columns indicating movie genre with 0-1 encoding where 1 denotes that the movie is of the corresponding genre. 
	In the \texttt{u.user} file, there are \num{943} users with the following information: \texttt{user id}, \texttt{age}, \texttt{gender}, \texttt{occupation} (see \texttt{u.occupation} file for details) and \texttt{zip code}.
	\item[\texttt{MovieLens Tag Genome Dataset}] 
	This dataset contains tagging information of \num{9734} movies and \num{1128} tags. 
	In particular, the \texttt{tag\_relevance} file contains the relevance of all tags for all movies reported on a continuous scale from 0 to 1, where 1 indicates strong relevance.
\end{description}


%------------------------------------------------------------------------------
\subsection{Research Questions}\label{subsec:questions}

\paragraph{Prediction Modeling}

Our first research question is to construct a predictive model for the user ratings using the available information. 
In particular, we wish to produce a model that is able to accurately predict the movie rating (for some movie already in the dataset) by a given user (also in the dataset). 
This problem is largely inspired from the Netflix prize \citep{bennett2007netflix} where contestant where asked to come up with the best predictive model for user ratings.
The resulting model could then be part of a \textit{recommendation system} where the predicted rating could be used as input to produce adequate personalized recommendations.

\paragraph{Exploratory Analysis}

A secondary research question we are interested in is to analyze the relationship between the available information and user ratings. 
For example, we could look for genres and tags that are related to movies with better ratings. 
Then, we can perform more granular analyses using the demographic data: this could allow to extract correlations between population groups and movie interests. 
The insights recovered from such analyses could be relevant for decision-making such as identifying which movies to produce or which population groups to target with advertisement.

%------------------------------------------------------------------------------
\section{Methodology}\label{sec:method}

%------------------------------------------------------------------------------
\subsection{Data Pre-processing}\label{subsec:method.preprocess}

The \texttt{MovieLens 100K Dataset} and the \texttt{MovieLens Tag Genome Dataset} have both been extensively cleaned by \texttt{GroupLens}\footnote{See the two \texttt{README} files for details: \url{http://files.grouplens.org/datasets/movielens/ml-100k-README.txt} and \url{http://files.grouplens.org/datasets/tag-genome/README.html}}. 
Thus, the main pre-processing we have to perform is the merging of the different datasets and the creation of the training and testing sets.

%------------------------------------------------------------------------------
\subsubsection{Merging the Datasets}\label{subsubsec:method.preprocess.merge}

First, the three datasets in \texttt{MovieLens 100K Dataset}, corresponding to user data, movie data and the ratings, have unique IDs which allows us to easily match them. 
There were no ratings which we were unable to match to users and/or movies in these datasets.

Second, the \texttt{MovieLens Tag Genome Dataset} also has unique IDs identifying movies, but they differ from those in the \texttt{MovieLens 100K Dataset}. 
Hence, we resort to matching the movie on the movie name. 
Direct matching of the strings allowed of to match a large proportion ($\sim$80\%) of the movies. 
There were also some movie that we were able to match using simple rules. 
For example, the movie names include the year of publication which were often mismatched by a year and prevented direct matching. 
Also, other movie names included the original name (in a foreign language) in either of the two datasets which prevented direct matching, but could still be detected. 
Finally, visual inspection (mostly by hand) of the remaining unmatched movies allowed to identify a few additional matches.
In total, we were able to match \num{1558} out of the \num{1681} in the \texttt{MovieLens 100K Dataset}. 
We therefore dropped all ratings of the movies which we could not matched. Fortunately, only very marginal movies did not make the cut and only \num{588} ratings out of \num{100000} had to be dropped: the resulting dataset therefore is composed of \num{99412} ratings on \num{1558} movies by \num{943} users. 

%------------------------------------------------------------------------------
\subsubsection{Data Subsetting}\label{subsubsec:method.preprocess.subset}

Upon joining the different datasets, we further subset the data in order to insure adequate representation of all included movies. 
In particular, we identify that some movies have small frequency (some appearing only once, for example). 
To fix this problem, we omit all ratings of movies which appear less than 20 times in the dataset. 
The final dataset then contains \num{94692} ratings on \num{935} movies; all \num{943} users remain in the dataset.

%------------------------------------------------------------------------------
\subsubsection{Data Splitting}\label{subsubsec:method.preprocess.split}

In order to assess the performance of the various models we consider, we proceed to the usual training-testing splitting. 
The training set consists of 75\% of the dataset (\num{71035} ratings) and the testing set of 25\% of the data (\num{23657} ratings). 
For consistency of results, the splitting was kept constant throughout the analysis.
To insure adequate representation of all movies in each sets, we proceeded to a stratified sampling of ratings within movies.

Furthermore, the training set was split into cross-validation sets in order to perform model tuning and model selection. 
In particular, the \num{71035} ratings were each assigned to one of 5 folds randomly, yielding training sets of size \num{56828} and validations sets of size \num{14207}. 
Again, this splitting was kept constant throughout the analysis.

%------------------------------------------------------------------------------
\subsection{Modeling}\label{subsec:method.models}

%------------------------------------------------------------------------------
\subsubsection{K-Nearest-Neighbors}\label{subsubsec:method.models.knn}

The \textit{$K$-nearest-neighbors} ($K$-NN) method is a non-parametric predictive model. 
Given a dataset of $n$ examples $(\bx_i, y_i)_{i=1}^n$, the prediction for a new $\bx$ is obtained as follows: find the $K$ indices $i_1\ddd i_K\in[n]$ such that the distances $d(\bx, \bx_{i_k})$ are minimized and aggregate the responses $y_{i_1}\ddd y_{i_K}$ into the prediction $\hat{y}$.
To completely determine a $K$-NN model, we need to specify the number of neighbors $K$, the distance function $d$ as well as the aggregation method.

%------------------------------------------------------------------------------
\paragraph{Distance function.}\label{par:method.models.knn.distance}

Our feature space consists predominantly of three types of information: movie genres (19 dimensions, encoded as 0/1), movie tags (1128 dimensions, in $[0,1]$) and user information (24 dimensions, various). Thus, our feature space has \num{1171} dimensions. 

We consider the Euclidean distance $d(\bx,\bx')=\Vert\bx-\bx'\Vert_2$ for our distance function, but we proceed to some transformation and parameterization to control the behavior of the distance. 

First, we standardize the features to get a mean of 0 and a variance of 1 across all examples. This step is crucial for any $K$-NN model using a general distance such as the Euclidean distance since features with different scales will have a lot more weight in the total distance. For example, all of our features are between 0 and except for the user age which varies from 7 to 73 and if we do not standardize this features, the $K$-NN will only match examples of very similar ages irrespectively of the other features.

Second, to account for the disproportional dimensions of the three groups of features as well as the relative importance of these groups, we introduce two parameters in the distance function. We fix the genre contribution to the distance to 1 and consider two multiplying factors $\alpha_\text{tags}, \alpha_\text{user}\geqslant 0$, respectively for tags and user information. Then, we transform the standardized features by scaling the correponding groups of features:
\begin{equation*}
	\bx:=(\bx_\text{genres}, \bx_\text{tags}, \bx_\text{user})
	\quad\mapsto\quad
	\tilde{\bx}:=(\bx_\text{genres}, \alpha_\text{tags}\bx_\text{tags}, \alpha_\text{user}\bx_\text{user})
\end{equation*}
This rescaling has the effect of inflating or deflating the contribution of a group of features to the total distance; tuning $\alpha_\text{tags}$ and $\alpha_\text{user}$ can therefore improve the performance of the model by using a more adequate distance.

The features naturally encode the movie and the user. Indeed, two examples of ratings on the same movies will have a distance discount as $1147$ features will be identical and do not contribute to the distance at all. Similarly ratings made by the same user will have a distance discount as $24$ features will be identical. Then, for appropriate values of $\alpha_\text{tags}$ and $\alpha_\text{user}$, we expect the set neighbors of some $\bx$ to include ratings made by the same users as well as ratings on the same movie.

%------------------------------------------------------------------------------
\paragraph{Aggregation.}\label{par:method.models.knn.agg}

Since our responses---the ratings---take discrete numerical values, we consider two aggregation methods. First, the \textit{regression} approach consists of simply averaging the $K$ responses: $\hat{y} = \frac 1K \sum_{k=1}^{K} y_{i_k}$. Second, the \textit{classfication} approach is to set the prediction $\hat{y}$ using a majority vote: $\hat{y} = \argmax_{y\in[5]}\sum_{k=1}^{K} \ind(y=y_{i_k})$. It is worth noting that the classification approach loses the ordinal property of ratings: if the $K$ neighbors have ratings equal to $(1,1,5,5,5)$, then the prediction would be $5$ for classification while regression would predict $3.4$.

%------------------------------------------------------------------------------
\paragraph{Implementation details.}\label{par:method.models.knn.impl}

We implement our $K$-NN models using the \texttt{sklearn.neighbors} module \citep{scikit-learn}: the classification predictions are made using \texttt{KNeighborsClassifier} and the regression predictions are made using \texttt{KNeighborsRegressor}. We use default settings except, obviously, for the number of neighbors. Our model has four tuning directions: aggregation method, number of neighbors and the two multiplers $\alpha_\text{tags},\alpha_\text{user}\geqslant 0$.

%------------------------------------------------------------------------------
\subsubsection{Neural Networks}\label{subsubsec:method.models.nn}

Our second predictive model uses a neural network (NN) approach. As input, we have the movie id, the movie genre and tags, the user id and information; as output, we have the rating. 
To fully define the network architecture, we need to specify how we treat the ids, the hidden layers structure, the final transformation and the loss function as well as the weight decay parameter. 
A graphical representation of the NN can be found in \Cref{fig:method.models.nn}.

%------------------------------------------------------------------------------
\paragraph{Movie and user embeddings.}\label{par:method.models.nn.embed}

While genre, tags and user details contains \textit{some} information about the movie and user, they do not capture the full description of these two object with respect to the ratings. 
In particular, without these ids, two movies with identical features will be treated identically by the network even though one might be inherently better than the other (e.g., better ratings).
Similarly, two users with identical features cannot be distinguished even tough they might have different rating habits or movie preferences.
Also, simply encoding the ids in a \textit{one-hot} fashion does not abstract the latent features of interest, which are most likely shared between some movies and some users. 
Thus, we augment the feature input with movie and user embeddings, which adds a fixed number of features, learned by the model, to each example. 


%------------------------------------------------------------------------------
\paragraph{Hidden layers.}\label{par:method.models.nn.hidden}

Given the augmented features, we include multiple fully-connected layers with linear nodes (with bias) linked through some activation function. We consider the ReLU activation function as well as different numbers of layers and of hidden nodes.

%------------------------------------------------------------------------------
\paragraph{Transformation and loss function.}\label{par:method.models.nn.transform}

As was mentioned in the description of the $K$-NN model (\Cref{subsubsec:method.models.knn}), our discrete numerical response can be treated in multiple ways: for this NN approach we consider five such treatments.

First, a simple regression scheme can be employed. In this case, we treat the ratings as a continuous output. We connect the last hidden layer to the ratings using an identity link and use the squared error loss as our optimization criterion.

Second and third, we can utilize the fact that our numerical outcome as a fixed, finite range. Indeed, since ratings take values between 1 and 5, we can force the network to produce predictions within or close to that range. In practice, this has the effect of not penalizing as much predictions that are away from the $[1,5]$ range: such predictions could be interpreted as that the model is really confident that the prediction should be at the boundary. To proceed as such we consider to simply clip the predictions to the range $[0,6]$, which is commonly known as the ReLU6 transformation. Alternatively, we consider a fixed sigmoid transformed mapped to the interval $(-2,8)$ which is fairly linear for the observed values but contracts predictions far from the true range closer to possible values. The three transformations are depicted in \Cref{fig:method.models.nn.functions}.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{functions_nn}
\caption{The three transformations considered at the output node for regression in a neural network. The dashed horizontal lines represent the boundary of observed ratings. }\label{fig:method.models.nn.functions}
\end{figure}

Fourth, we can treat our responses as five classes where only one is observed per example. In that case, we encode the ratings in the \textit{one-hot} fashion, that is, 4 gets encoded as $(0,0,0,1,0)$. Then, the final layer is transformed using the usual softmax function and the loss function used is the binary cross-entropy. Again, this encoding loses the ordinal nature of the ratings.

Fifth, we can choose a different encoding for the five classes that will reflect ordering of ratings. Indeed, we can encode a 4 as $(1,1,1,1,0)$ and model the responses in the multi-label classification way. Then, since all encoded responses have this ordinal structure, the NN will reproduce it in its predictions. In that case, we perform a sigmoid transformation on the five final nodes before comparing them to the encoded ratings; the loss function is again the binary cross-entropy.


\begin{figure}
\centering
	\includegraphics[scale=0.7]{nn}
	\caption{Neural network architecture.}
	\label{fig:method.models.nn}
\end{figure}

%\begin{figure}
%\centering
%\input{./diagrams/nn.tex}
%\caption{Neural network architecture described in \Cref{subsubsec:method.models.nn}. Black nodes represent observed quantities; white nodes, hidden variables; grey squares, functions.}
%\label{fig:method.models.nn}
%\end{figure}

%------------------------------------------------------------------------------
\paragraph{Implementation details.}\label{par:method.models.nn.impl}

Our NN models are implemented using the \texttt{PyTorch} module \citep{paszke2017automatic} using stochastic gradient descent. We use a fixed learning rate of \num{0.01}, batch size of \num{512} and number of epochs of \num{50}; the activation functions are chosen to be the ReLU function in all cases to reduce the tuning space. For this model, we have six tuning directions: movie and user embedding sizes, hidden layers number and sizes, the final transformation and weight decay parameter value. We also compare whether including the external information improves on simply using the two embeddings.

%------------------------------------------------------------------------------
\subsubsection{Matrix Completion}\label{subsubsec:method.models.svd}
Building a recommendation system by doing matrix completion is one of \textit{collaborative filtering} techniques. This means that we will try to suggest movies to an user by inspecting the ratings of ``similar'' users. To be more specific, it is assumed that the taste, or the ratings, made by users follows some low-rank structure, and use that assumption to make prediction. The idea of using SVD for movie recommendation is simple but it turns out to be successful in application. The winner in the Netflix prize competition used SVD as the main technique in their algorithm \citep{bennett2007netflix}. 

%------------------------------------------------------------------------------
\paragraph{Model description.}\label{par:method.models.svd.model}
In this model, we use 2 hyper-parameters, which are the embedding dimension $k$ and the number of iterations $I$. We set up and train the training data as follows.

\begin{enumerate}
\item Create a pivoted matrix $A$ in which rows are users and columns are movies. The $(i,j)$-cell of the matrix is the rating of user i for movie j, and is \texttt{NA} if there is no information about that in the training set. We also create a masked matrix which indicate which cell in pivot matrix is \texttt{NA}. After that, we fill the \texttt{NA} cells in $A$ with \texttt{0}.
\item Repeat $I$ times: 
\begin{itemize}
	\item Fill all the non-masked cell in $A$ with the original visible rating.
	\item Approximate $A$ by its truncated SVD of rank $k$. 
\end{itemize}
\end{enumerate}

By iterating two steps above, it allows us to reuse the visible information over and over, and extract the low rank structure of ratings. 


%------------------------------------------------------------------------------


%------------------------------------------------------------------------------
\paragraph{Implementation details.}\label{par:method.models.svd.impl}
We use the \texttt{svds} function from \texttt{scipy.sparse.linalg} module \citep{2020SciPy-NMeth} to compute truncated SVD of pivoted matrix and repeat the two steps above to get the reconstruction of users-movies ratings matrix. After that, the information from the reconstructed matrix is used as predictions. This model has two turning parameters: the dimension $k$ and number of iterations $I$.  


%------------------------------------------------------------------------------
\subsubsection{Restricted Boltzmann Machine}\label{subsubsec:method.models.rbm}
Similar to matrix completion, Restricted Boltzmann Machine (RBM) is also a collaborative filtering method. It assumes ratings of users are affected by some latent binary variables. We construct a probabilistic model where there is $F$ hidden nodes in total and a bipartite graph for each user connecting the hidden variables with the visible ratings. 

%------------------------------------------------------------------------------
\paragraph{Model description.}\label{par:method.models.rbm.model}

\begin{figure}
	\input{./diagrams/rbm.tex}
	\caption{Restricted Boltzmann Machine in \Cref{subsubsec:method.models.rbm}. Each user has a graphical model connecting hidden variables and visible ratings. Weights $W_{ij}^{k}$ are shared among users.\label{fig:method.models.rbm}}
\end{figure}



Denote hidden variables by $\textbf{h} = (h_1, h_2,\dots, h_F)$ and suppose there are $K$ rating scores in total ($5$ for our data set). For now, to reduce the burden of notation, we only consider the model for each user and will talk about the connection between them later. For a given user, suppose $m$ movies were rated and write the visible ratings $\textbf{V} = (v_i^k)_{i,k}$ where $v_i^k = 1$ if movie $m$ was rated $k$ and $0$ otherwise. The generative model is defined by
\begin{equation}\label{GenModelRBM}
p(\textbf{V}, \textbf{h}) = \dfrac{1}{Z} \exp(-E(\textbf{V}, \textbf{h})),
\end{equation}
where $Z = \sum_{\textbf{V}', \textbf{h}'}$ is the normalization. The term $E(V, h)$ is so called \textit{energy} and defined by
\begin{equation}\label{EnergyRBM}
E(V,h) = - \sum_{i=1}^{m} \sum_{j=1}^{F} \sum_{k=1}^{K} W_{ij}^k h_j v_i^k - \sum_{i=1}^{m} \sum_{k=1}^{K} b_i^k v_i^k - \sum_{j=1}^{F} h_j b_j,
\end{equation}
where $W_{ij}^k$ is the weight connecting $h_j$ to $v_i^k$, $b_i^k$ is a bias term for $v_i^k$ and $b_j$ is the bias for $h_j$. Therefore, each user has a different bipartite graph model and visible ratings $\textbf{V}$, but they all share the same weight $(W_{ij}^k)$ and biases $(b_i^k), (b_j)$.   

From this, we can calculate the conditional probability 
\begin{equation}\label{pv|h}
p(v_i^k = 1| \textbf{h}) = \dfrac{\exp(b_{i}^{k} + \sum_{j=1}^{F} h_j W_{ij}^k)}{\sum_{l=1}^{k} \exp(b_{i}^{l} + \sum_{j=1}^{F} h_j W_{ij}^l)}, 
\end{equation}
and
\begin{equation}\label{ph|v}
p(h_j = 1 | \textbf{V}) = \sigma(b_j + \sum_{i=1}^{m}\sum_{k=1}^{K} v_i^k W_{ij}^{k}),
\end{equation}
where $\sigma$ is the sigmoid function. The marginal distribution for $\textbf{V}$ is
$$p(\textbf{V}) = \dfrac{1}{Z} \sum_{\textbf{h'}} \exp(-E(\textbf{V}, \textbf{h'})).$$
Our aim is to find $(W_{ij}^{k}, b_{i}^{k}, b_j)_{i,j,k}$ maximizing the marginal distribution for visible ratings $\textbf{V}$, which corresponds to the \textit{maximum likelihood} method. We will employ gradient descent to find the optimal weights. 


%------------------------------------------------------------------------------
\paragraph{Implementation details.}\label{par:method.models.rbm.impl}

We build and train a RBM model by ourselves using basic modules such as \texttt{numpy} \citep{numpy2011}. There are three turning parameters in the model: the number of hidden nodes, the number of Gibbs samplings in Contrastive Divergence, and the learning rate. Many details in the implementation is taken from \cite{hinton2012practical}.


%------------------------------------------------------------------------------
\section{Results}\label{sec:results}

We perform 5-fold cross-validation on many instances of our models against the training set and produce the \textit{mean squared error} (MSE) and prediction accuracy averaged over the 5 folds. For models with numerical predictions, we assign the predicted rating to the nearest integer in the range $[1,5]$.  Models with class predictions simply use the class label as their numerical prediction. 

It is worthwhile to mention that we are in a classification problem with 5 classes so a random assignment would produce 20\% accuracy: we observe accuracies close to 40\%, which is already a great improvement. To get a sense of ``good'' MSE values, we report that the winners of the Netflix prize \citep{bennett2007netflix} have a test score of \num{0.8567} on a similarly structured dataset.

We first detail the results for the four models we consider, noting some observation on their CV performance. Then, we proceed to a comparison of the four models in terms of CV and testing.

%------------------------------------------------------------------------------
\subsection{$K$-Nearest-Neighbors}\label{sebsec:results.knn}

Upon training and testing 35 instances of the $K$-NN model described in \Cref{subsubsec:method.models.knn} with varying tuning parameters, we obtain the results depicted in \Cref{tab:results.knn} which contains a selection of the best models.

As could be expected, regression aggregation performs better in terms of MSE while classification aggregation performs better in terms of prediction accuracy. Also, the value of the tuning parameters $\alpha_\text{user}$ and $\alpha_\text{tags}$ for these best models seems to align with their purpose. Indeed, we observe that the best models require to inflate the importance of user information and deflate that of tags.

The  $K$-NN models is particularly inefficient computationally: when $K$ increases from 5 to 100, training time increases from minutes to hours.


%------------------------------------------------------------------------------
\subsection{Neural Network}\label{sebsec:results.nn}

We trained hundreds of instances of the NN approach described in \Cref{subsubsec:method.models.nn}; the results for a selection of the best models can be found in \Cref{tab:results.nn}. We make some observations with regards to the tuning parameters.

First, we observe that including the external features (genre, tags, user info) greatly improves the model as we see a significant reduction in MSE prediction accuracy. 

Second, we note that the ordinal transformation does not appear in the best results: inspecting the complete logs, we find that this method performs better than classification in terms of MSE but worse in terms of prediction and is therefore in the middle of the pack in both categories. The classification scheme yields decent prediction performance, but we see even better accuracy from regression approaches. The three regression transformation---identity, ReLU6 and sigmoid---seem to perform rather similarly with the sigmoid transform being slightly worse generally.

Third, the best performing models in terms of CV metrics seem to require simpler hidden layers structures: while the experiments included networks with up to four hidden layers, the best models generally contain only two. This exhibits the benefit of using CV for model selection as it prevents overfitting. Similarly, the best models generally require some regularization---through weight decay---in order to exhibit good generalization metrics.

In terms of computing time, the NN models we consider train for 50 epochs in around 1 minute on GPU.




%------------------------------------------------------------------------------
\subsection{Matrix Completion}\label{sebsec:results.svd}
We trained around 100 instances of matrix completion models described in \Cref{subsubsec:method.models.svd}. We choose to present some models with its parameters. From the result, in \Cref{tab:results.svd}, we can see some facts about turning parameters as below.

For the embedded dimension $k$, if it is chosen to be too small, the model will not capture enough the complexity of the data and lead to the underfitting phenomena. If $k$ is large, the computational time will relatively increase but the prediction is not getting better, and there is even the overfitting phenomena. 

For the iterative number $I$ to use SVD, it can be seen that small $I$ leads to underfitting model meanwhile large $I$ leads to overfitting model. This can be interpreted that if we reuse the training data too many times, the model will tend to prefer the training data and the test error will eventually increase. If $k$ and $I$ are large at the same time, the model will be surely overfitting.

It is amazing that this model only needs a few lines of code but the performance is comparable to what the complicated models like Neural network or Restricted Boltzmann Machine do. The idea behind this method is also innocent and it is computationally efficient (most of them only take less than a second to train in a 4 cores CPU machine).     

%------------------------------------------------------------------------------
\subsection{Restricted Bolztmann Machine}\label{sebsec:results.rbm}

We trained around 100 instances of RBM model as describes in \Cref{subsubsec:method.models.rbm}. We choose to present some models with its parameters. From the result, in \Cref{tab:results.rbm}, we can see some facts about turning parameters as below.

For the number of hidden nodes, it turns out to be the best when set it around 15-20. If this number is too small, the model will be underfitting, but setting this number to large does not help the model to predict better.

For the number of Gibbs samplings to use in Contrastive Divergence, it is plausible to set it 1, because it does not help to improve the model significantly when it increases, but slow down the learning phase much (we need to do sampling for every (movie, user) couple.)

It is claimed in \cite{10.1145/1273496.1273596} that RBM paper can outperform SVD models in a fine-tuned parameters scenario. However, we observe something contrary to that here. It may due to the fact that the research team at the University of Toronto spent several years to achieve the expertise in training RBM models. In the time to the final report, we will keep trying improve our RBM model and see how far can we go compared to what is presented in that paper.

%------------------------------------------------------------------------------
\subsection{Model Comparison}\label{sebsec:results.model}

\Cref{tab:results.model} contains a comparison of the best version of each of the four models we considered. 

The $K$-NN models perform worse than $NN$ and matrix completion and require much more computing time. This approach does not seem very promising as a predictive model for movie ratings.

The $NN$ models yield interesting results and can be trained efficiently. They achieve lower CV MSE than matrix completion, but their generalization to the testing set is worse. It is worthwhile to note that they do not achieve the performance level of matrix completion even though more information is included in the model. Indeed, matrix completion does not use movie genre and tags nor user information.

The SVD matrix completion model results show that this simple model can outperform many other complicated models. Simon Funk, a participant in the Netflix prize competition \citep{bennett2007netflix}, used this simple model and finished in third place.\footnote{\url{https://sifter.org/~simon/journal/20061211.html}} Its computational efficiency, compared to all three other models, is also a very appealing feature.

The RBM model, while a beautiful latent variable model, really needs time and expertise to be able to set it up correctly and implemenent efficiently.  

Overall, matrix completion using SVD out-performs all other models in MSE and classification accuracy on the testing set. Therefore, we choose that approach for the subsequent analyses.

\input{./table/model.tex}


%------------------------------------------------------------------------------
\section{Exploratory Analysis}\label{sec:explore}

In order to extract insight out of our predictive model, we propose to ways to explore the relationship between the extra information---movie genres and tags, user demographics---and the predicted ratings. Ultimately, what our model tells us about the predicted ratings can be translated into knowledge about the population of movies and the population of users. The proposed methods serve mostly as proofs of concept or blueprints more than actual analyses: we are mostly interested on how we can retrieve information from the model rather than the actual information itself.

%------------------------------------------------------------------------------
\subsection{Correlating Predictions with External Information}\label{subsec:explore.corr}

Our first approach relies only on the predictive nature of our model and thus do not depend on the actual type of model selected. As a first step, we make every user rate every movie in order to remove the sampling bias introduced by the users choosing which movie to watch (and then rate them). The matrix completion model provide us with that for free as the low-rank approximation contains exactly those prediction. Second, we standardize the predictions by subtracting the mean predicted rating of each user from all its predictions: this has the effect of removing the effect of users having different scales. Indeed, a rating of 4 might not mean the same thing for each user and we need to account for that. Then, we treat the predicted rating differences as ``observed'' and study how they vary with respect to both populations. For categorical features, we can average predicted rating differences within each subgroups. For numerical features, we can study the variation using a fitted smooth curve.

As an example, we consider the variation of predicted rating differences with respect to movie genres, user gender and user age. Since both genres and gender are categorical variables, we simply subset the predictions according to all combinations of those features. Then, within each subset, we fit a generalized additive model (GAM)\footnote{Fitted using the \texttt{pyGAM} package \citep{pygam}.} between the predicted rating differences and age. The results can be found in \Cref{fig:explore.corr.gam}.

\begin{figure}
    \centering
	\includegraphics[scale=0.7]{rating_diff_per_age_gender_genre}
	\caption{Variation of predicted rating differences with repect to movie genre, user gender and user age. For each subset given by a genre-gender combination, a GAM is fitted against user age. Solid lines represent the fitted mean; dashed lines corresponds to 95\% confidence intervals around the fitted mean.\label{fig:explore.corr.gam}}
\end{figure}

If we consider \textit{Documentary} movies, we can see that younger males and older females tend to rate such movies better than their average while younger females and older males tends to rate them around their average. \textit{Thriller} and \textit{Sci-Fi} movies seems to be under-appreciated by the whole user population while \textit{Drama} movies seems to be generally well-received by all users.

%------------------------------------------------------------------------------
\subsection{Bi-Clustering using SVD}\label{subsec:explore.cluster}

Our second approach relies on the output of the matrix completion ratings model. The singular value decomposition resulting from the matrix completion produces left- and right- singular vectors within $U$ and $V$, respectively. The matrix $U\in\bbR^{n_{\text{movies}}\times 4}$ then contains then contains a 4-dimensional embedding of each movie; the matrix $V\in\bbR^{4\times n_{\text{users}}}$ contains a 4-dimensional embedding of the users. Studying these embeddings with respect to external information can infrom us on the relationship between the population of movies and of movies through ratings.

\Cref{fig:explore.cluster.movies,fig:explore.cluster.users} contain scatter plots of these embeddings. Visual inspection 

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
	\centering
	\includegraphics[width=\textwidth]{movie_clusters}
	\caption{ted mean.\label{fig:explore.cluster.movies}}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.5\textwidth}
	\centering
	\includegraphics[width=\textwidth]{user_clusters}
	\caption{d mean.\label{fig:explore.cluster.users}}
    \end{subfigure}
    \caption{Caption place holder}
\end{figure*}



\begin{figure}[t]
	\centering
	\includegraphics[width=0.6\textwidth]{user_movie_clusters}
	\caption{d mean.\label{fig:explore.cluster.pairs}}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=\textwidth]{movie_clusters_genre}
	\caption{ted mean.\label{fig:explore.cluster.genre}}
\end{figure}


\begin{figure}[t]
	\centering
	\includegraphics[width=\textwidth]{user_clusters_occupation}
	\caption{d mean.\label{fig:explore.cluster.occupation}}
\end{figure}
%------------------------------------------------------------------------------
\section{Conclusion}\label{sec:conc}



%------------------------------------------------------------------------------
\clearpage
\newpage
\bibliographystyle{imsart-nameyear}
\bibliography{../utils/references}{}


%------------------------------------------------------------------------------
\clearpage
\newpage
\appendix 

%------------------------------------------------------------------------------
\section{Contributions}\label{sec:contrib}

The work was subdivided as follows. Simon worked on $K$-NN and NN models, Dat on matrix completion and RBM models. Each implemented, trained and analyzed the respective models; the respective part of the report were written accordingly. The exploratory data analysis was performed jointly: Simon wrote the first method and Dat wrote the bi-clustering section. The rest of the report was written jointly.

%------------------------------------------------------------------------------
\section{Derivations for Restricted Bolztmann Machine}\label{sec:rbm}

%------------------------------------------------------------------------------
\paragraph{Learning.}\label{par:method.models.rbm.learning}

We need to compute the gradient of $\log p(\textbf{V})$ in order to perform gradient ascent. By the chain rule
\begin{align*}
\dfrac{\partial \log p(\textbf{V})}{\partial W_{ij}^{k}} &= \dfrac{1}{p(\textbf{V})} \dfrac{\partial p(\textbf{V})}{\partial W_{ij}^{k}} \\
& = \dfrac{1}{p(\textbf{V})} \left(\dfrac{\sum_{\textbf{h}} \onebb_{[h_j = 1, v_{i}^{k} = 1]} p(\textbf{V}, \textbf{h})}{Z} - \dfrac{p(\textbf{V}) \sum_{\boldsymbol{\nu}, \textbf{h}}\onebb_{[h_j = 1, \boldsymbol{\nu}_{i}^{k} = 1]} p(\boldsymbol{\nu}, \textbf{h})}{Z} \right)\\
& = \Ebb_{h|\textbf{V}}(v_i^k h_j) - \Ebb(\nu_i^k h_j)\\
& =: \cexp{v_i^k h_j}_{data} - \cexp{\nu_i^k h_j}_{model}
\end{align*}
where $\cexp{\cdot}_{subscript}$ denotes the conditional expectation with respect to the subscript. 
Similarly, we have
\begin{equation}
\dfrac{\partial p(\textbf{V})}{\partial b_j}  = \Ebb_{h|\textbf{V}} (h_j) - \Ebb(h_j) =  \cexp{h_j}_{data} - \cexp{h_j}_{model},
\end{equation}
and 
\begin{equation}
\dfrac{\partial p(\textbf{V})}{\partial b_i^k}  = v_i^k - \Ebb(\nu_i^k) = v_i^k - \cexp{\nu_i^k}_{model}.
\end{equation}
In each equation, it is customary to call the first term \textit{positive statistics} and second term \textit{negative statistics}. Hence, we have the analytical representation of gradient of weights and biased terms. In every equation, the first term is easy to compute thanks to \eqref{ph|v}. However, computing the terms $\cexp{\nu_{i}^{k}}_{model}, \cexp{h_j}_{model}$, and $\cexp{\nu_{i}^{k}}_{model}$ requires to take the sum over all value of $\boldsymbol{\nu}, \textbf{h}$, which takes exponential time and makes the algorithm inefficiently. We will instead use the \textit{Contrastive Divergence} (CD) method \citep{hinton2012practical} which consists of approximating $\cexp{\nu_i^k h_j}_{model}$ with $\cexp{\nu_i^k h_j}_{recon}$, an approximated reconstruction of $\cexp{\nu_i^k h_j}_{model}$ based on an idea similar to the Gibbs' sampler.

%------------------------------------------------------------------------------
\paragraph{Computing gradient using Constrastive Divergence.}\label{par:method.models.rbm.grad}

The idea behind Contrastive Divergence \citep{hinton2012practical} is to approximate the gradient using the difference of two Kullback-Leibler divergences and ignore one trickly term. Although this is a crude approximation, it turns out to work really well in many applications. The Constrastive Divergence with $n$ steps ($CD_n$) can be interpreted as follows. Given the visible ratings $\textbf{V}$, first we sample binary value for hidden units $h_{data} = h$ by equation \eqref{ph|v}. Then we do $n$ steps of Gibbs' sampling, each contains two intermediary steps
\begin{enumerate}
	\item Sample $\boldsymbol{\nu} \leftarrow \boldsymbol{h}$ based on equation \eqref{pv|h}.
	\item Sample $\boldsymbol{h} \leftarrow \boldsymbol{\nu}$ based on equation \eqref{ph|v}.
\end{enumerate}
To derive the positive statistics, we use the value of data $\textbf{V}$ and $h_{data}$. Although we can calculate it analytically using \eqref{ph|v}, using the sample values can reduce the noise when we take the difference with the negative statistics. Hence, we have
$$\cexp{v_i^k h_j}_{data} \leftarrow v_i^k h_{data, j}, \quad \cexp{h_j}_{data} \leftarrow h_{data, j}$$
When collect the negative statistics, it is advised in \cite{hinton2012practical} that in the last step, we should only collect $\boldsymbol{h}$ as the probability $p(\textbf{h}|\boldsymbol{\nu})$ (but not sample from it) to get the updates
$$\cexp{\nu_i^k h_j}_{recon} \leftarrow \nu_i^k h_{j},\quad \cexp{h_j}_{recon} \leftarrow h_{data, j},\quad \cexp{\nu_i^k}_{recon} \leftarrow \nu_i^k.$$

%------------------------------------------------------------------------------
\paragraph{Making predictions.}\label{par:method.models.rbm.pred}

Given a set of visible unit $\textbf{V}$, we can predict the rating for a new movie by using Bayes' rule and marginalization of $\textbf{h}$:
\begin{align*}
p(v_q^{k} =  1 |\textbf{V}) & \propto p(v_q^{k} = 1, \textbf{V})  \\
&  \propto \sum_{\textbf{h}} p(v_q^{k} = 1, \textbf{V}, \textbf{h})\\
& \propto \exp(b_k^q) \prod_{j=1}^{q} \sum_{h_j\in \{0,1\}} \exp(\sum_{il} v_i^{l} h_j W_{ij}^{l} + h_j W_{qj}^{k} + h_jb_j)\\
& = \exp(b_k^q) \prod_{j=1}^{q} \left( 1 +  \exp(\sum_{il} v_i^{l} W_{ij}^{l} +  W_{qj}^{k} + b_j)\right)
\end{align*}


\clearpage
\newpage
%------------------------------------------------------------------------------
\section{Detailed results}\label{sec:res}
\Cref{tab:results.knn,tab:results.svd,tab:results.rbm,tab:results.nn} contain some of the best models trained for each of the four prediction methods considered. The complete logs can be found alongside the project's code at \url{https://github.com/fontaine618/507-Project/}.

\input{./table/knn.tex}
\input{./table/svd.tex}
\input{./table/rbm.tex}
\input{./table/nn.tex}


\end{document}
